{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "#from xception_gcn_seg import XceptionGCNSegmentation\n",
    "#from resnet_gcn_seg import ResnetGCNSegmentation\n",
    "#from desnet_gcn_seg import DensenetGCNSegmentation\n",
    "#from MobileNetDenseASPP import DenseASPP\n",
    "#from resnext_gcn_seg import ResNeXtGCNSegmentation\n",
    "#from threeloss_Densenet_DenseASPP_plus import Densenet_DenseASPP_Multiloss\n",
    "#from threeloss_Densenet_DenseASPP_concate import Densenet_DenseASPP_Multiloss\n",
    "#from Densenet_DenseASPP import DenseASPP\n",
    "from resnet_gcn_pab import ResnetGCN_PAB\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResnetGCN_PAB()\n",
    "model_name = 'snapshot_125_G_model'\n",
    "net = nn.DataParallel(net).cuda()\n",
    "checkpoint = torch.load(model_name)\n",
    "net.load_state_dict(checkpoint)\n",
    "net.eval()\n",
    "norm_mean = [0.406, 0.456, 0.485]\n",
    "norm_std = [0.225, 0.224, 0.229]\n",
    "norm = {'mean': norm_mean, 'std': norm_std}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('val/val.txt','r')\n",
    "lines = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines:\n",
    "    imagepath = line.split(' ')[0]\n",
    "    img = cv2.imread(imagepath)\n",
    "    try:\n",
    "        img_rs = cv2.resize(img,(512,512), interpolation=cv2.INTER_CUBIC)\n",
    "    except:\n",
    "        continue\n",
    "    else:\n",
    "        input_tensor = img_rs.transpose((2, 0, 1))\n",
    "        input_tensor = torch.from_numpy(input_tensor).float()\n",
    "        input_tensor = input_tensor.div(255.0)\n",
    "        normalize = transforms.Normalize(norm['mean'], norm['std'])\n",
    "        input_tensor = normalize(input_tensor)\n",
    "        input_tensor = torch.unsqueeze(input_tensor, 0)\n",
    "        input_tensor = Variable(input_tensor, volatile=True)\n",
    "        outputs = net(input_tensor.cuda())\n",
    "        img_mask = outputs['output'].cpu().data.numpy()\n",
    "        img_mask = np.squeeze(img_mask).astype('uint8')\n",
    "        mask_name = imagepath.split('/')[-1][:-4] + '_mask.png'\n",
    "        cv2.imwrite('temp/'+mask_name, img_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _iou(a, b, label):\n",
    "        s = (a == label).astype(np.float32) + (b == label).astype(np.float32)\n",
    "        #print (s)\n",
    "        ins = (s == 2).sum()\n",
    "        #print ('ins:'+str(ins))\n",
    "        union = (s >= 1).sum()\n",
    "        return ins*1.0 / union if union > 0 else 0\n",
    "\n",
    "score_dict = {}\n",
    "for idx in range(6):\n",
    "        score_dict['class_%s' % idx] = 0\n",
    "        score_dict['num_class_%s' % idx] = 0\n",
    "for root,direction,files in os.walk('temp/'):\n",
    "    for file in files:\n",
    "        output = cv2.imread(os.path.join(root,file),0)\n",
    "        if file[0] == '0':         \n",
    "            groundtruth = cv2.imread('anno/'+file,0)\n",
    "        else:\n",
    "            groundtruth = cv2.imread('anno/'+file[:-9]+'_seg.png',0)\n",
    "        try:\n",
    "            groundtruth = cv2.resize(groundtruth,(512,512))\n",
    "        except:\n",
    "            continue\n",
    "        else:\n",
    "            label_num = np.unique(groundtruth)\n",
    "            #print (label_num)\n",
    "            for idx in label_num:\n",
    "                iou = _iou(output, groundtruth, idx)\n",
    "                #if iou:\n",
    "                score_dict['class_%s' % idx] = score_dict['class_%s' % idx]+iou\n",
    "                score_dict['num_class_%s' % idx] = score_dict['num_class_%s' % idx] + 1\n",
    "for idx in range(6):\n",
    "    score_dict['average_iou_%s'%idx] = score_dict['class_%s' % idx]/score_dict['num_class_%s' % idx]\n",
    "score_dict['mean_iou']=(score_dict['average_iou_0']+score_dict['average_iou_1']+score_dict['average_iou_2']+score_dict['average_iou_3']+score_dict['average_iou_4']+score_dict['average_iou_5'])/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average_iou_0': 0.83447789873528899,\n",
       " 'average_iou_1': 0.43061558865880684,\n",
       " 'average_iou_2': 0.32600047046697112,\n",
       " 'average_iou_3': 0.55820846085006548,\n",
       " 'average_iou_4': 0.34360946821345695,\n",
       " 'average_iou_5': 0.64455752107594477,\n",
       " 'class_0': 1364.3713644321974,\n",
       " 'class_1': 1074.385893703723,\n",
       " 'class_2': 870.74725661727985,\n",
       " 'class_3': 1642.2492918208927,\n",
       " 'class_4': 1000.5907714375866,\n",
       " 'class_5': 1876.9515013731511,\n",
       " 'mean_iou': 0.52291156800008898,\n",
       " 'num_class_0': 1635,\n",
       " 'num_class_1': 2495,\n",
       " 'num_class_2': 2671,\n",
       " 'num_class_3': 2942,\n",
       " 'num_class_4': 2912,\n",
       " 'num_class_5': 2912}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for roots,directions,files in os.walk('img_pick_3000/'):\n",
    "    for imagepath in files:\n",
    "        \n",
    "        img = cv2.imread(os.path.join(roots,imagepath))\n",
    "        img_rs = cv2.resize(img,(512,512), interpolation=cv2.INTER_CUBIC)\n",
    "        input_tensor = img_rs.transpose((2, 0, 1))\n",
    "        input_tensor = torch.from_numpy(input_tensor).float()\n",
    "        input_tensor = input_tensor.div(255.0)\n",
    "        normalize = transforms.Normalize(norm['mean'], norm['std'])\n",
    "        input_tensor = normalize(input_tensor)\n",
    "        input_tensor = torch.unsqueeze(input_tensor, 0)\n",
    "        input_tensor = Variable(input_tensor, volatile=True)\n",
    "        outputs = net(input_tensor.cuda())\n",
    "        img_mask = outputs['output'].cpu().data.numpy()\n",
    "        img_mask = np.squeeze(img_mask).astype('uint8')\n",
    "        mask_name = imagepath.split('/')[-1][:-4] + '_mask.png'\n",
    "        cv2.imwrite('resnet_gcn_pab/'+mask_name, img_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
